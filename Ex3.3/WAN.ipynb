{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as opt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data.dataset as Dataset\n",
    "import torch.utils.data.dataloader as Dataloader\n",
    "from torch.autograd import Variable\n",
    "import pickle as pkl\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from utils import tools,model,pde_staff,validation\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 't2/'\n",
    "'''\n",
    "t1: 2000pts, 2, 1, 20000\n",
    "\n",
    "'''\n",
    "dataname = '2000pts'\n",
    "path = 'results/WAN/t2/'\n",
    "\n",
    "bw = 10000\n",
    "val_interval = 50\n",
    "\n",
    "Ksol = 2\n",
    "Kadv = 1\n",
    "\n",
    "max_outer_iter = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adverse(\n",
       "  (input_layer): Linear(in_features=2, out_features=30, bias=True)\n",
       "  (Hidden1): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (Hidden2): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (Hidden3): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (output_layer): Linear(in_features=30, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solNet = model.solution()\n",
    "#solNet = model.adverse()\n",
    "advNet = model.adverse() \n",
    "\n",
    "solNet.apply(model.init_weights)\n",
    "advNet.apply(model.init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "if not os.path.exists(path+\"sol_plots/\"):\n",
    "    os.mkdir(path+\"sol_plots/\")\n",
    "\n",
    "if not os.path.exists(path+'adv_plots/'):\n",
    "    os.mkdir(path+\"adv_plots/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2) (500, 2)\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset/\"+dataname,'rb') as pfile:\n",
    "    d_c = pkl.load(pfile)\n",
    "    b_c = pkl.load(pfile)\n",
    "print(d_c.shape,b_c.shape)\n",
    "\n",
    "dx,dy = np.split(d_c,2,axis=1)\n",
    "bx,by = np.split(b_c,2,axis=1)\n",
    "\n",
    "\n",
    "#For simul, no cost evaluation, and we need data on whole domain.\n",
    "\n",
    "tdx,tdy,tbx,tby = tools.from_numpy_to_tensor([dx,dy,bx,by],[True,True,False,False])\n",
    "\n",
    "#bdrydat = torch.zeros([len(tbx),1])\n",
    "\n",
    "with open(\"dataset/gt_on_{}\".format(dataname),'rb') as pfile:\n",
    "    y_gt = pkl.load(pfile)\n",
    "    f_np = pkl.load(pfile)\n",
    "    bd_np = pkl.load(pfile)\n",
    "\n",
    "f,ygt,bdrydat = tools.from_numpy_to_tensor([f_np,y_gt,bd_np],[False,False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def L2InnerProd(u,v,x,y):\n",
    "    u_values = u(x,y) \n",
    "    if type(v) is torch.Tensor:\n",
    "        v_values = v \n",
    "    else:\n",
    "        v_values = v(x,y) \n",
    "    return torch.mean(torch.mul(u_values,v_values))\n",
    "\n",
    "def A(sol,adv,rhs,x,y):\n",
    "    sol_out = sol(x,y)\n",
    "    sol_x = torch.autograd.grad(sol_out.sum(),x,create_graph=True)[0]\n",
    "    sol_y = torch.autograd.grad(sol_out.sum(),y,create_graph=True)[0]\n",
    "\n",
    "    adv_out = adv(x,y)\n",
    "    adv_x = torch.autograd.grad(adv_out.sum(),x,create_graph=True)[0]\n",
    "    adv_y = torch.autograd.grad(adv_out.sum(),y,create_graph=True)[0]\n",
    "\n",
    "    lhs_itg = torch.mean(sol_x * adv_x + sol_y * adv_y)\n",
    "    rhs_itg = L2InnerProd(adv,rhs,x,y)\n",
    "\n",
    "    return lhs_itg - rhs_itg\n",
    "\n",
    "\n",
    "def compute_lossmin():\n",
    "    adv_norm_2 = L2InnerProd(advNet,advNet,tdx,tdy)\n",
    "    A_value = A(solNet,advNet,f,tdx,tdy)\n",
    "\n",
    "    L_int = torch.square(A_value) / adv_norm_2\n",
    "    #L_int = torch.log(torch.square(A_value)) - torch.log(adv_norm_2)\n",
    "    #Compute L_bdry\n",
    "    bdry_out = solNet(tbx,tby)\n",
    "\n",
    "    L_bdry = torch.square(bdry_out - bdrydat).mean()\n",
    "\n",
    "    #Compute the loss\n",
    "    loss_min = L_int + bw * L_bdry\n",
    "    print(L_bdry.detach().numpy(),L_int.detach().numpy())\n",
    "\n",
    "    return loss_min.detach().numpy(),L_int.detach().numpy(),L_bdry.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = validation.record_forward()\n",
    "\n",
    "def hook(optimizer,nploss):\n",
    "    #stateitems = list(optimizer.state.items())\n",
    "    #epoch = stateitems[0][1]['n_iter']\n",
    "    rec.updateTL(nploss)\n",
    "    epoch = rec.epoch\n",
    "    if epoch%val_interval==0:\n",
    "        with torch.enable_grad():\n",
    "            loss,Lint,Lbdry = compute_lossmin()\n",
    "            rec.validate(solNet)\n",
    "    \n",
    "        rec.updatePL(loss,Lint,Lbdry)\n",
    "        \n",
    "        print(\"Running u optimization at epoch {}...\".format(epoch))\n",
    "        with torch.no_grad():\n",
    "            losslist = rec.losslist\n",
    "            with torch.no_grad():\n",
    "                rec.plotinfo(path)\n",
    "                validation.plot_2D_scatter(solNet,path+\"sol_plots/sol{}.png\".format(epoch))\n",
    "                validation.plot_2D_scatter(advNet,path+\"adv_plots/adv{}.png\".format(epoch))\n",
    "\n",
    "                torch.save(solNet,'{}sol.pt'.format(path))\n",
    "                torch.save(advNet,'{}adv.pt'.format(path))\n",
    "                with open(path+\"losshist.pkl\",'wb') as pfile:\n",
    "                    pkl.dump(losslist,pfile)\n",
    "\n",
    "                print(\"INFO SAVED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer_sol = opt.LBFGS(solNet.parameters(),stephook=hook,line_search_fn=\"strong_wolfe\",max_iter=200,max_eval=200,tolerance_grad=1e-15, tolerance_change=1e-15, history_size=100)\n",
    "#optimizer_adv = opt.LBFGS(advNet.parameters(),line_search_fn=\"strong_wolfe\",max_iter=100,max_eval=100,tolerance_grad=1e-15, tolerance_change=1e-15, history_size=100)\n",
    "optimizer_sol = opt.Adam(solNet.parameters(),lr=1e-4)\n",
    "optimizer_adv = opt.Adam(advNet.parameters(),lr=1e-3)\n",
    "#optimizer_sol = opt.Adagrad(solNet.parameters(),lr=0.015)\n",
    "#optimizer_adv = opt.Adagrad(advNet.parameters(),lr=0.04)\n",
    "\n",
    "def closure_sol():\n",
    "    optimizer_sol.zero_grad()\n",
    "    optimizer_adv.zero_grad()\n",
    "    tools.checkgrad([tdx,tdy])\n",
    "\n",
    "    #Compute L_int \n",
    "    adv_norm_2 = L2InnerProd(advNet,advNet,tdx,tdy)\n",
    "    A_value = A(solNet,advNet,f,tdx,tdy)\n",
    "    L_int = torch.square(A_value) / adv_norm_2\n",
    "    #L_int = torch.log(torch.square(A_value)) - torch.log(adv_norm_2)\n",
    "\n",
    "    #Compute L_bdry\n",
    "    bdry_out = solNet(tbx,tby)\n",
    "\n",
    "    L_bdry = torch.square(bdry_out - bdrydat).mean()\n",
    "\n",
    "    #Compute the loss\n",
    "    loss_min = L_int + bw * L_bdry\n",
    "    #print(L_int,L_bdry)\n",
    "    #Backward \n",
    "    #print(loss_min)\n",
    "    loss_min.backward()\n",
    "\n",
    "    return loss_min.detach().numpy()\n",
    "\n",
    "def closure_adv():\n",
    "    optimizer_sol.zero_grad()\n",
    "    optimizer_adv.zero_grad()\n",
    "    tools.checkgrad([tdx,tdy])\n",
    "\n",
    "    #Compute L_int \n",
    "    adv_norm_2 = L2InnerProd(advNet,advNet,tdx,tdy)\n",
    "    A_value = A(solNet,advNet,f,tdx,tdy)\n",
    "\n",
    "    L_int = torch.square(A_value) / adv_norm_2\n",
    "    #L_int = torch.log(torch.square(A_value)) - torch.log(adv_norm_2)\n",
    "    \n",
    "    #Compute the loss\n",
    "    loss_max = - L_int\n",
    "\n",
    "    #Backward \n",
    "    loss_max.backward()\n",
    "\n",
    "    return loss_max.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003040056305117068 93.9672639151208\n",
      "Running u optimization at epoch 50...\n",
      "INFO SAVED\n",
      "0.00022590625782805912 93.91441120356322\n",
      "Running u optimization at epoch 100...\n",
      "INFO SAVED\n",
      "0.00017359856630529559 93.68700356047856\n",
      "Running u optimization at epoch 150...\n",
      "INFO SAVED\n",
      "0.00013896921304980703 93.25935350876384\n",
      "Running u optimization at epoch 200...\n",
      "INFO SAVED\n",
      "0.00011907500110951728 92.6466032589226\n",
      "Running u optimization at epoch 250...\n",
      "INFO SAVED\n",
      "0.00011005615548313206 91.87675199421699\n",
      "Running u optimization at epoch 300...\n",
      "INFO SAVED\n",
      "0.0001089550009034582 90.97625939183885\n",
      "Running u optimization at epoch 350...\n",
      "INFO SAVED\n",
      "0.00011409780169064002 89.96244854353547\n",
      "Running u optimization at epoch 400...\n",
      "INFO SAVED\n",
      "0.00012497647761229233 88.84169869399052\n",
      "Running u optimization at epoch 450...\n",
      "INFO SAVED\n",
      "0.0001420061876965303 87.61104843215597\n",
      "Running u optimization at epoch 500...\n",
      "INFO SAVED\n",
      "0.00016631891585553861 86.26129170093849\n",
      "Running u optimization at epoch 550...\n",
      "INFO SAVED\n",
      "0.0001995849146245034 84.78072174955491\n",
      "Running u optimization at epoch 600...\n",
      "INFO SAVED\n",
      "0.00024375498857457523 83.15908330567089\n",
      "Running u optimization at epoch 650...\n",
      "INFO SAVED\n",
      "0.0003006487367728934 81.39130368959549\n",
      "Running u optimization at epoch 700...\n",
      "INFO SAVED\n",
      "0.00037139853262694667 79.4805569268988\n",
      "Running u optimization at epoch 750...\n",
      "INFO SAVED\n",
      "0.0004558124373451834 77.4399373632938\n",
      "Running u optimization at epoch 800...\n",
      "INFO SAVED\n",
      "0.0005517727259725858 75.29130877328303\n",
      "Running u optimization at epoch 850...\n",
      "INFO SAVED\n",
      "0.0006548999721238431 73.059078318218\n",
      "Running u optimization at epoch 900...\n",
      "INFO SAVED\n",
      "0.0007588471660131514 70.75678381616405\n",
      "Running u optimization at epoch 950...\n",
      "INFO SAVED\n",
      "0.0008563520028747901 68.36758159732032\n",
      "Running u optimization at epoch 1000...\n",
      "INFO SAVED\n",
      "0.000939912042446112 65.8246370691839\n",
      "Running u optimization at epoch 1050...\n",
      "INFO SAVED\n",
      "0.0010012731059811303 62.99050878794756\n",
      "Running u optimization at epoch 1100...\n",
      "INFO SAVED\n",
      "0.0010309496061466715 59.620885534335\n",
      "Running u optimization at epoch 1150...\n",
      "INFO SAVED\n",
      "0.0010210092675673195 55.31312218475001\n",
      "Running u optimization at epoch 1200...\n",
      "INFO SAVED\n",
      "0.0009709721601149249 49.58861103567848\n",
      "Running u optimization at epoch 1250...\n",
      "INFO SAVED\n",
      "0.0009065898367622691 41.51802500052914\n",
      "Running u optimization at epoch 1300...\n",
      "INFO SAVED\n",
      "0.0007918441869684731 32.27394233378694\n",
      "Running u optimization at epoch 1350...\n",
      "INFO SAVED\n",
      "0.0006612367500249007 22.784874844036217\n",
      "Running u optimization at epoch 1400...\n",
      "INFO SAVED\n",
      "0.0005548645571616386 17.10342559188055\n",
      "Running u optimization at epoch 1450...\n",
      "INFO SAVED\n",
      "0.0006753245881441327 14.531308571008202\n",
      "Running u optimization at epoch 1500...\n",
      "INFO SAVED\n",
      "0.000662062946823875 15.16047204984973\n",
      "Running u optimization at epoch 1550...\n",
      "INFO SAVED\n",
      "0.0006287040570049744 14.89843263706488\n",
      "Running u optimization at epoch 1600...\n",
      "INFO SAVED\n",
      "0.0005664817414100493 13.510278827433604\n",
      "Running u optimization at epoch 1650...\n",
      "INFO SAVED\n",
      "0.000551991581063904 14.463061293737827\n",
      "Running u optimization at epoch 1700...\n",
      "INFO SAVED\n",
      "0.0005176000578006425 14.086770275357159\n",
      "Running u optimization at epoch 1750...\n",
      "INFO SAVED\n",
      "0.0005001950972106335 15.378234996787562\n",
      "Running u optimization at epoch 1800...\n",
      "INFO SAVED\n",
      "0.0004965211957850235 16.680344694836037\n",
      "Running u optimization at epoch 1850...\n",
      "INFO SAVED\n",
      "0.0004260742000128387 18.81644660031366\n",
      "Running u optimization at epoch 1900...\n",
      "INFO SAVED\n",
      "0.00034054501275797495 17.603772822266553\n",
      "Running u optimization at epoch 1950...\n",
      "INFO SAVED\n",
      "0.00038026745803730545 19.952875430741045\n",
      "Running u optimization at epoch 2000...\n",
      "INFO SAVED\n",
      "0.000340873838866229 23.511719055913055\n",
      "Running u optimization at epoch 2050...\n",
      "INFO SAVED\n",
      "0.00038591892574660455 29.053316710963806\n",
      "Running u optimization at epoch 2100...\n",
      "INFO SAVED\n",
      "0.0005793939256713072 32.027756726062194\n",
      "Running u optimization at epoch 2150...\n",
      "INFO SAVED\n",
      "0.00036437587097026955 37.36398094824752\n",
      "Running u optimization at epoch 2200...\n",
      "INFO SAVED\n",
      "0.0006373565070509124 57.102384441424086\n",
      "Running u optimization at epoch 2250...\n",
      "INFO SAVED\n",
      "0.00048026902498662184 57.813674835941704\n",
      "Running u optimization at epoch 2300...\n",
      "INFO SAVED\n",
      "0.0004291266852541319 58.161590369021575\n",
      "Running u optimization at epoch 2350...\n",
      "INFO SAVED\n",
      "0.0003945697167447829 58.072679892535575\n",
      "Running u optimization at epoch 2400...\n",
      "INFO SAVED\n",
      "0.0003662168668586852 57.608637888185626\n",
      "Running u optimization at epoch 2450...\n",
      "INFO SAVED\n",
      "0.0003396172136597263 56.816624742480755\n",
      "Running u optimization at epoch 2500...\n",
      "INFO SAVED\n",
      "0.0003137949045146989 55.72370679536439\n",
      "Running u optimization at epoch 2550...\n",
      "INFO SAVED\n",
      "0.0002897869648599869 54.384584145869056\n",
      "Running u optimization at epoch 2600...\n",
      "INFO SAVED\n",
      "0.00027658882233965744 52.92881448757142\n",
      "Running u optimization at epoch 2650...\n",
      "INFO SAVED\n",
      "0.00026340859769751634 51.32002828836615\n",
      "Running u optimization at epoch 2700...\n",
      "INFO SAVED\n",
      "0.0002557395781227693 49.78952675597833\n",
      "Running u optimization at epoch 2750...\n",
      "INFO SAVED\n",
      "0.0002525803072955347 48.75879550072527\n",
      "Running u optimization at epoch 2800...\n",
      "INFO SAVED\n",
      "0.0002497272366497699 48.52424117565537\n",
      "Running u optimization at epoch 2850...\n",
      "INFO SAVED\n",
      "0.00024759491616731526 48.66939432922543\n",
      "Running u optimization at epoch 2900...\n",
      "INFO SAVED\n",
      "0.00024265587682453888 48.675829736527966\n",
      "Running u optimization at epoch 2950...\n",
      "INFO SAVED\n",
      "0.0002336124569755996 48.583178666168656\n",
      "Running u optimization at epoch 3000...\n",
      "INFO SAVED\n",
      "0.00022497111780263041 48.582022146682824\n",
      "Running u optimization at epoch 3050...\n",
      "INFO SAVED\n",
      "0.00021667971697968534 48.96647208773712\n",
      "Running u optimization at epoch 3100...\n",
      "INFO SAVED\n",
      "0.00021067850084761537 49.765329066231715\n",
      "Running u optimization at epoch 3150...\n",
      "INFO SAVED\n",
      "0.00021149333686351602 50.93520612311883\n",
      "Running u optimization at epoch 3200...\n",
      "INFO SAVED\n",
      "0.00022372383165564493 52.60329392338543\n",
      "Running u optimization at epoch 3250...\n",
      "INFO SAVED\n",
      "0.0001952267545671788 41.74594857891607\n",
      "Running u optimization at epoch 3300...\n",
      "INFO SAVED\n",
      "0.0001380838956882718 45.26158852112899\n",
      "Running u optimization at epoch 3350...\n",
      "INFO SAVED\n",
      "0.0001912072493198044 4.539711165266061\n",
      "Running u optimization at epoch 3400...\n",
      "INFO SAVED\n",
      "0.00021865391042598742 0.9821046377587835\n",
      "Running u optimization at epoch 3450...\n",
      "INFO SAVED\n",
      "0.0002295167708016126 2.5771507018158886\n",
      "Running u optimization at epoch 3500...\n",
      "INFO SAVED\n",
      "0.00032416223146259325 50.00179554976451\n",
      "Running u optimization at epoch 3550...\n",
      "INFO SAVED\n",
      "0.00024369097305170566 49.58005877806256\n",
      "Running u optimization at epoch 3600...\n",
      "INFO SAVED\n",
      "0.00026714555874581713 48.90021129733724\n",
      "Running u optimization at epoch 3650...\n",
      "INFO SAVED\n",
      "0.00025346977148377973 44.95957467557969\n",
      "Running u optimization at epoch 3700...\n",
      "INFO SAVED\n",
      "0.00027566338315221855 51.74985396843269\n",
      "Running u optimization at epoch 3750...\n",
      "INFO SAVED\n",
      "0.00013787003098694378 56.94882152676549\n",
      "Running u optimization at epoch 3800...\n",
      "INFO SAVED\n",
      "0.00027624578596266235 48.847333866480795\n",
      "Running u optimization at epoch 3850...\n",
      "INFO SAVED\n",
      "0.0002868172773098378 57.35946051355187\n",
      "Running u optimization at epoch 3900...\n",
      "INFO SAVED\n",
      "0.0001353875612329745 52.744706580037395\n",
      "Running u optimization at epoch 3950...\n",
      "INFO SAVED\n",
      "0.0001603780291301654 57.65760725105803\n",
      "Running u optimization at epoch 4000...\n",
      "INFO SAVED\n",
      "0.00026123428984673526 55.3843930097445\n",
      "Running u optimization at epoch 4050...\n",
      "INFO SAVED\n",
      "0.00018707311091670212 56.92007800832107\n",
      "Running u optimization at epoch 4100...\n",
      "INFO SAVED\n",
      "0.00014370508295447355 57.77327203041432\n",
      "Running u optimization at epoch 4150...\n",
      "INFO SAVED\n",
      "0.00013115612127170557 55.527846760884735\n",
      "Running u optimization at epoch 4200...\n",
      "INFO SAVED\n",
      "0.00031948999868627414 60.43894696942402\n",
      "Running u optimization at epoch 4250...\n",
      "INFO SAVED\n",
      "0.00018622069608760722 57.13359776978598\n",
      "Running u optimization at epoch 4300...\n",
      "INFO SAVED\n",
      "0.0001352478494562867 50.816282188406355\n",
      "Running u optimization at epoch 4350...\n",
      "INFO SAVED\n",
      "0.00014503392469522193 57.89927904868241\n",
      "Running u optimization at epoch 4400...\n",
      "INFO SAVED\n",
      "0.00011078151400375588 59.230890231560366\n",
      "Running u optimization at epoch 4450...\n",
      "INFO SAVED\n",
      "0.00010944549995486586 57.67456709090913\n",
      "Running u optimization at epoch 4500...\n",
      "INFO SAVED\n",
      "0.00011914119039269441 53.301848648615454\n",
      "Running u optimization at epoch 4550...\n",
      "INFO SAVED\n",
      "0.00010958781932415317 58.081623325314354\n",
      "Running u optimization at epoch 4600...\n",
      "INFO SAVED\n",
      "0.00021715195368791538 61.21411457506274\n",
      "Running u optimization at epoch 4650...\n",
      "INFO SAVED\n",
      "0.0002589265970723549 54.0956966360061\n",
      "Running u optimization at epoch 4700...\n",
      "INFO SAVED\n",
      "0.00017376670710320802 59.481241948463655\n",
      "Running u optimization at epoch 4750...\n",
      "INFO SAVED\n",
      "0.0001273443565180124 59.84775376451238\n",
      "Running u optimization at epoch 4800...\n",
      "INFO SAVED\n",
      "0.00012679374590508172 60.30671383026256\n",
      "Running u optimization at epoch 4850...\n",
      "INFO SAVED\n",
      "0.00015450673809496552 61.58317612067363\n",
      "Running u optimization at epoch 4900...\n",
      "INFO SAVED\n",
      "0.00015466019575101746 61.104770758853206\n",
      "Running u optimization at epoch 4950...\n",
      "INFO SAVED\n",
      "0.00012579922816848688 59.09047367328441\n",
      "Running u optimization at epoch 5000...\n",
      "INFO SAVED\n",
      "0.00014196086927605067 62.10360811493776\n",
      "Running u optimization at epoch 5050...\n",
      "INFO SAVED\n",
      "9.303065787425728e-05 60.89926607385206\n",
      "Running u optimization at epoch 5100...\n",
      "INFO SAVED\n",
      "0.0004804617494103062 58.779097169751616\n",
      "Running u optimization at epoch 5150...\n",
      "INFO SAVED\n",
      "0.00029700146651117244 42.15755069808695\n",
      "Running u optimization at epoch 5200...\n",
      "INFO SAVED\n",
      "0.0003564397139524605 52.731394812936045\n",
      "Running u optimization at epoch 5250...\n",
      "INFO SAVED\n",
      "0.0001736691649491521 57.29121406663234\n",
      "Running u optimization at epoch 5300...\n",
      "INFO SAVED\n",
      "0.00036175083407015846 57.870757006997586\n",
      "Running u optimization at epoch 5350...\n",
      "INFO SAVED\n",
      "0.00017187444568863002 62.81782395075557\n",
      "Running u optimization at epoch 5400...\n",
      "INFO SAVED\n",
      "0.00017075800340216613 62.77523390371199\n",
      "Running u optimization at epoch 5450...\n",
      "INFO SAVED\n",
      "0.00014763185516363813 63.77266503513777\n",
      "Running u optimization at epoch 5500...\n",
      "INFO SAVED\n",
      "0.0001287464807274726 64.426238204852\n",
      "Running u optimization at epoch 5550...\n",
      "INFO SAVED\n",
      "0.0001255200260566753 65.21715736879838\n",
      "Running u optimization at epoch 5600...\n",
      "INFO SAVED\n",
      "0.00012009304164943103 65.64737743083218\n",
      "Running u optimization at epoch 5650...\n",
      "INFO SAVED\n",
      "0.00012137692536063935 65.97580151238765\n",
      "Running u optimization at epoch 5700...\n",
      "INFO SAVED\n",
      "0.00012222442907846488 66.17121048141287\n",
      "Running u optimization at epoch 5750...\n",
      "INFO SAVED\n",
      "0.00012154912680626071 66.2699728321359\n",
      "Running u optimization at epoch 5800...\n",
      "INFO SAVED\n",
      "0.00012484355385206352 63.992404553331454\n",
      "Running u optimization at epoch 5850...\n",
      "INFO SAVED\n",
      "0.00012202258484291412 63.26131338107809\n",
      "Running u optimization at epoch 5900...\n",
      "INFO SAVED\n",
      "0.0001303073241581169 65.95009648574003\n",
      "Running u optimization at epoch 5950...\n",
      "INFO SAVED\n",
      "0.00014803827200937815 66.24224839958367\n",
      "Running u optimization at epoch 6000...\n",
      "INFO SAVED\n",
      "0.00021820641969749115 64.54564229074091\n",
      "Running u optimization at epoch 6050...\n",
      "INFO SAVED\n",
      "0.00016835093883394147 63.86562219703255\n",
      "Running u optimization at epoch 6100...\n",
      "INFO SAVED\n",
      "0.00017577353258165014 65.63895856565306\n",
      "Running u optimization at epoch 6150...\n",
      "INFO SAVED\n",
      "0.00015206206672799166 63.06745993842832\n",
      "Running u optimization at epoch 6200...\n",
      "INFO SAVED\n",
      "0.00012606891751446532 66.4253448265847\n",
      "Running u optimization at epoch 6250...\n",
      "INFO SAVED\n",
      "0.00012489129156879297 66.02595241044315\n",
      "Running u optimization at epoch 6300...\n",
      "INFO SAVED\n",
      "0.00011520544740093803 65.33988852517999\n",
      "Running u optimization at epoch 6350...\n",
      "INFO SAVED\n",
      "0.00010935205973080839 65.77262015658269\n",
      "Running u optimization at epoch 6400...\n",
      "INFO SAVED\n",
      "9.385236631576586e-05 66.40826835872147\n",
      "Running u optimization at epoch 6450...\n",
      "INFO SAVED\n",
      "0.0002106653528044755 65.62002052981809\n",
      "Running u optimization at epoch 6500...\n",
      "INFO SAVED\n",
      "0.00011880686451984043 66.32527040150985\n",
      "Running u optimization at epoch 6550...\n",
      "INFO SAVED\n",
      "0.00010485911245830029 66.5881065283606\n",
      "Running u optimization at epoch 6600...\n",
      "INFO SAVED\n"
     ]
    }
   ],
   "source": [
    "for _ in range(max_outer_iter):\n",
    "    for isol in range(Ksol):\n",
    "        optimizer_sol.step(closure_sol)\n",
    "    for iadv in range(Kadv):\n",
    "        optimizer_adv.step(closure_adv)\n",
    "\n",
    "    loss = float(closure_sol())\n",
    "    hook(None,loss)\n",
    "    #print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
